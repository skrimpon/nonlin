{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Symbol-level simulation\n",
    "Let's first consider a simple symbol-level simulation. We consider a single-input\n",
    "multiple-output (SIMO) system. First, we generate the transmit symbols\n",
    "$$\\mathbf{x}$$ based on i.i.d complex Gaussian distribution with zero mean and variance 1.\n",
    "Then, we consider a single path channel $\\mathbf{w}$ with i.i.d uniform phase in\n",
    "$[0,2\\pi]$. For the receiver, we consider $n_\\mathrm{rx}=16$ receive antennas.\n",
    "For each design option $\\theta$ we create a different radio-frequency front-end (RFFE),\n",
    "that can be described by a unique non-linear function $\\Phi_\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "in_df = pd.read_csv(r'../datasets/rx_1/idata_1.csv')\n",
    "p0_df = pd.read_csv(r'../datasets/rx_1/param_0_1_1.csv')\n",
    "p1_df = pd.read_csv(r'../datasets/rx_1/param_1_1_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fc = float(p0_df['fc'])\n",
    "fs = float(p0_df['fs'])\n",
    "nit = int(p0_df['nit'])\n",
    "nrx = int(p0_df['nrx'])\n",
    "nsnr = int(p0_df['nsnr'])\n",
    "nx = int(p0_df['nx'])\n",
    "ndsgn = 4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Random tx data\n",
    "x = np.char.replace(np.array(in_df['x'],dtype=str),'i','j').astype(np.complex)\n",
    "\n",
    "# Channel w\n",
    "tmp = []\n",
    "for i in range(1,nrx+1):\n",
    "  tmp.append(np.char.replace(np.array(in_df['w_'+str(i)],dtype=str),'i','j').astype(np.complex))\n",
    "\n",
    "w = np.empty([nx, nrx], dtype=complex)\n",
    "for irx in range(nrx):\n",
    "  w[:,irx] = tmp[irx]\n",
    "\n",
    "# Received data with no noise\n",
    "tmp = []\n",
    "for i in range(1,nrx+1):\n",
    "  tmp.append(np.char.replace(np.array(in_df['y_'+str(i)],dtype=str),'i','j').astype(np.complex))\n",
    "\n",
    "y = np.empty([nx, nrx], dtype=complex)\n",
    "for irx in range(nrx):\n",
    "  y[:,irx] = tmp[irx]\n",
    "\n",
    "\n",
    "# Received data at the antenna at various rx power levels\n",
    "tmp = []\n",
    "for i in range(1,nsnr*nrx+1):\n",
    "  tmp.append(np.char.replace(np.array(in_df['yant_'+str(i)],dtype=str),'i','j').astype(np.complex))\n",
    "\n",
    "r = np.empty([nx, nrx, nsnr], dtype=complex)\n",
    "for isnr in range(nsnr):\n",
    "  for irx in range(nrx):\n",
    "    r[:,irx,isnr] = tmp[isnr*nrx + irx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Output of the RFFE non-linear function Phi(r)\n",
    "\n",
    "y_rffe = np.empty([nx, nrx, nsnr, ndsgn], dtype=complex)\n",
    "x_hat = np.empty([nx, nsnr, ndsgn], dtype=complex)\n",
    "\n",
    "for idsgn in range(ndsgn):\n",
    "  out_df = pd.read_csv(r'../datasets/rx_1/odata_'+str(idsgn+1)+'_1.csv')\n",
    "\n",
    "  tmp = []\n",
    "  for i in range(1,nsnr*nrx+1):\n",
    "    tmp.append(np.char.replace(np.array(out_df['yrffe_'+str(i)],dtype=str),'i','j').astype(np.complex))\n",
    "\n",
    "  for isnr in range(nsnr):\n",
    "    for irx in range(nrx):\n",
    "      y_rffe[:,irx,isnr,idsgn] = tmp[isnr*nrx + irx]\n",
    "\n",
    "  # Predicted tx data\n",
    "  tmp = []\n",
    "  for i in range(1,nsnr+1):\n",
    "    tmp.append(np.char.replace(np.array(out_df['xhat_'+str(i)],dtype=str),'i','j').astype(np.complex))\n",
    "\n",
    "  for isnr in range(nsnr):\n",
    "      x_hat[:,isnr,idsgn] = tmp[isnr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "irx = 0\n",
    "isnr = 30\n",
    "plt.rcParams[\"figure.figsize\"] = (7.5, 7.5)\n",
    "for idsgn in range(ndsgn):\n",
    "  plt.subplot(2,2,idsgn+1)\n",
    "  plt.plot(r[:,irx,isnr].real, y_rffe[:,irx,isnr,idsgn].real, 's')\n",
    "  plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16, 31, 4)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rffe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isnr = 10\n",
    "idsgn = 1\n",
    "y_itr = np.squeeze(y_rffe[:,:,isnr,idsgn])\n",
    "r_itr = r[:,:,isnr]\n",
    "y_itr.shape\n",
    "r_itr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# loss_val = tf.cast(tf.keras.losses.MSE(r_itr, y_itr),tf.float32)\n",
    "# print('Loss Value {}'.format(loss_val))\n",
    "# print('Mean Loss {}'.format(np.mean(loss_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inverter():\n",
    "    def __init__(self, number_of_rx):\n",
    "        self.size = number_of_rx\n",
    "        self.training = True \n",
    "        # Create a `Sequential` model and add a Dense layer as the first layer.\n",
    "        self.model = tf.keras.models.Sequential()\n",
    "        self.model.add(tf.keras.Input(shape=(self.size,) , name=\"Phi_Input\"))\n",
    "        self.model.add(tf.keras.layers.Dense(self.size*2, activation='relu', name=\"Dense_1\"))\n",
    "        self.model.add(tf.keras.layers.Dense(self.size, name=\"R_output\"))\n",
    "        self.model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "        print('The model summar: \\n {}'.format(self.model.summary()))\n",
    "\n",
    "    def predict(self, phi):\n",
    "        return self.model.predict(phi)\n",
    "\n",
    "    def fit(self, phi_tr, r_tr, phi_val, r_val, batch_size = 64, epochs=5,verbose=0):\n",
    "        self.model.fit(phi_tr, r_tr, batch_size=batch_size,epochs=epochs,validation_data=(phi_val, r_val) ,verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "R_output (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 1,072\n",
      "Trainable params: 1,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The model summar: \n",
      " None\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "R_output (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 1,072\n",
      "Trainable params: 1,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The model summar: \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Create class\n",
    "myInv_amp = Inverter(y_itr.shape[1])\n",
    "myInv_phase = Inverter(y_itr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01312485+0.00591137j, -0.03260088+0.03690234j,\n",
       "        -0.02972109-0.00302277j, -0.02415562-0.04115967j,\n",
       "        -0.08682765-0.0243844j , -0.03269601-0.00114704j,\n",
       "         0.03570674+0.05329696j, -0.02096318+0.02800357j,\n",
       "        -0.04911027+0.05099002j,  0.02007129-0.02111798j,\n",
       "         0.06247738-0.00480635j,  0.02761505-0.02545828j,\n",
       "        -0.04079741+0.02889954j, -0.03800023+0.01587778j,\n",
       "         0.03189207-0.00419298j,  0.01300263-0.00308128j],\n",
       "       [-0.00456301-0.05826509j, -0.0868191 -0.00050798j,\n",
       "        -0.05241824-0.00794887j,  0.00772384+0.06944084j,\n",
       "         0.05267647-0.02170806j,  0.06595642+0.02329904j,\n",
       "        -0.01370055-0.07467655j, -0.02169121+0.06087913j,\n",
       "        -0.04287423-0.03919618j,  0.0032342 -0.04265234j,\n",
       "         0.04262974-0.05713014j,  0.05639004+0.04883357j,\n",
       "        -0.03365651-0.05425558j, -0.01429336-0.04584882j,\n",
       "        -0.01373651+0.02118902j,  0.04241338-0.00473619j],\n",
       "       [-0.00726111-0.05275457j, -0.07301712-0.01915377j,\n",
       "         0.08220121-0.01118958j, -0.04621575+0.02307253j,\n",
       "         0.05945776+0.06127382j,  0.09003114-0.02854959j,\n",
       "         0.02938397-0.03301141j, -0.02795952+0.07515234j,\n",
       "         0.09566733-0.02375412j,  0.05696922+0.01032982j,\n",
       "         0.08166156+0.06092019j,  0.02786279-0.00789293j,\n",
       "        -0.03921894-0.05751324j, -0.04343535+0.03341538j,\n",
       "         0.01077205-0.09353229j, -0.01277845-0.03903518j],\n",
       "       [ 0.01086985-0.03540283j,  0.03845042+0.02139088j,\n",
       "         0.01142766+0.01090648j,  0.01253638+0.00094681j,\n",
       "         0.00769037-0.00637241j,  0.00844279+0.04210061j,\n",
       "        -0.00797439+0.01204082j, -0.01239797+0.00877261j,\n",
       "         0.02038386+0.02306894j, -0.00840702-0.01224302j,\n",
       "         0.03011615+0.01799876j, -0.03154784-0.00125982j,\n",
       "         0.01131123+0.03219296j,  0.00248151+0.02559372j,\n",
       "        -0.0132992 +0.03964492j, -0.03439507-0.00882019j]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_itr[1:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (9000, 16)\n",
      "Shape of test (500, 16)\n",
      "Shape of valid (500, 16)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Complex data not supported\n[[-0.0412666 +0.01238431j -0.06532157+0.05071886j  0.03542907+0.00489855j\n  ...  0.04252053+0.02760351j -0.06542837+0.04102459j\n   0.03519216-0.04604568j]\n [-0.02207827-0.0078266j  -0.02316407-0.03731146j -0.00715607+0.00989477j\n  ...  0.04993407+0.05854175j  0.00104546-0.0132661j\n   0.03671542-0.01938713j]\n [-0.03179392+0.01238533j -0.04330196+0.02218541j  0.01039555-0.02630369j\n  ...  0.02536243-0.00335426j -0.01750864+0.05168657j\n  -0.00135085-0.00328434j]\n ...\n [-0.0089808 -0.03446439j -0.04490885+0.02452841j  0.02040876+0.00662291j\n  ...  0.0098938 +0.01210916j  0.01106963+0.03354875j\n   0.00374203+0.02969456j]\n [ 0.00852569-0.01935108j  0.0840827 -0.0286016j   0.00673851+0.02525897j\n  ...  0.01159253-0.04846113j  0.01631508-0.05060832j\n  -0.0183179 +0.04879481j]\n [-0.0062521 -0.00419877j -0.0203071 -0.003403j   -0.0099921 +0.01836443j\n  ... -0.00618264-0.01074328j -0.01193833+0.01626654j\n   0.03230237-0.05724273j]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComplexWarning\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mComplexWarning\u001b[0m: Casting complex values to real discards the imaginary part",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-e51fefad8b5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0minput_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0minput_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0moutput_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    694\u001b[0m             \u001b[0mTransformer\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \"\"\"\n\u001b[1;32m--> 696\u001b[1;33m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[0;32m    697\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                                 force_all_finite='allow-nan')\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    598\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                 raise ValueError(\"Complex data not supported\\n\"\n\u001b[0m\u001b[0;32m    601\u001b[0m                                  \"{}\\n\".format(array))\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Complex data not supported\n[[-0.0412666 +0.01238431j -0.06532157+0.05071886j  0.03542907+0.00489855j\n  ...  0.04252053+0.02760351j -0.06542837+0.04102459j\n   0.03519216-0.04604568j]\n [-0.02207827-0.0078266j  -0.02316407-0.03731146j -0.00715607+0.00989477j\n  ...  0.04993407+0.05854175j  0.00104546-0.0132661j\n   0.03671542-0.01938713j]\n [-0.03179392+0.01238533j -0.04330196+0.02218541j  0.01039555-0.02630369j\n  ...  0.02536243-0.00335426j -0.01750864+0.05168657j\n  -0.00135085-0.00328434j]\n ...\n [-0.0089808 -0.03446439j -0.04490885+0.02452841j  0.02040876+0.00662291j\n  ...  0.0098938 +0.01210916j  0.01106963+0.03354875j\n   0.00374203+0.02969456j]\n [ 0.00852569-0.01935108j  0.0840827 -0.0286016j   0.00673851+0.02525897j\n  ...  0.01159253-0.04846113j  0.01631508-0.05060832j\n  -0.0183179 +0.04879481j]\n [-0.0062521 -0.00419877j -0.0203071 -0.003403j   -0.0099921 +0.01836443j\n  ... -0.00618264-0.01074328j -0.01193833+0.01626654j\n   0.03230237-0.05724273j]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the input phi\n",
    "# Some issues with normalization we need to figure out\n",
    "\n",
    "#Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(y_itr, r_itr, test_size=0.1)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5)\n",
    "print('Shape of train {}'.format(X_train.shape))\n",
    "print('Shape of test {}'.format(X_test.shape))\n",
    "print('Shape of valid {}'.format(X_valid.shape))\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# input_scaler = StandardScaler()\n",
    "# input_scaler.fit(np.abs(X_train))\n",
    "\n",
    "# output_scaler = StandardScaler()\n",
    "# output_scaler.fit(y_train)\n",
    "\n",
    "# X_train = input_scaler.transform(X_train)\n",
    "# X_valid = input_scaler.transform(X_valid)\n",
    "# X_test = input_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# y_train = output_scaler.transform(y_train)\n",
    "# y_valid = output_scaler.transform(y_valid)\n",
    "# y_test = output_scaler.transform(y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Mean of the x train amp {}'.format(np.mean(X_train_amp)))\n",
    "print('Mean of the y train amp {}'.format(np.mean(y_train_amp)))\n",
    "\n",
    "\n",
    "\n",
    "# Get the amplitude and phase for models\n",
    "X_train_phase = np.angle(X_train)\n",
    "X_train_amp = np.abs(X_train)\n",
    "y_train_phase = np.angle(y_train)\n",
    "y_train_amp = np.abs(y_train)\n",
    "\n",
    "\n",
    "X_test_phase = np.angle(X_test)\n",
    "X_test_amp = np.abs(X_test)\n",
    "y_test_phase = np.angle(y_test)\n",
    "y_test_amp = np.abs(y_test)\n",
    "\n",
    "X_valid_phase = np.angle(X_valid)\n",
    "X_valid_amp = np.abs(X_valid)\n",
    "y_valid_phase = np.angle(y_valid)\n",
    "y_valid_amp = np.abs(y_valid)\n",
    "\n",
    "\n",
    "# mean_ratio = (np.mean(X_train_amp)/np.mean(y_train_amp))\n",
    "# y_train_amp *= mean_ratio\n",
    "# y_test_amp *= mean_ratio\n",
    "# y_valid_amp *= mean_ratio\n",
    "# np.mean(y_train_amp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.1707 - val_loss: 0.3828\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.3086 - val_loss: 0.2258\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2239 - val_loss: 0.1972\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2006 - val_loss: 0.1800\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1839 - val_loss: 0.1682\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1719 - val_loss: 0.1598\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1624 - val_loss: 0.1536\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1569 - val_loss: 0.1488\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1513 - val_loss: 0.1446\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1470 - val_loss: 0.1421\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1436 - val_loss: 0.1399\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1420 - val_loss: 0.1378\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1412 - val_loss: 0.1353\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1351 - val_loss: 0.1338\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1362 - val_loss: 0.1323\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1343 - val_loss: 0.1315\n",
      "Epoch 17/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1350 - val_loss: 0.1307\n",
      "Epoch 18/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1319 - val_loss: 0.1300\n",
      "Epoch 19/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1321 - val_loss: 0.1291\n",
      "Epoch 20/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1312 - val_loss: 0.1286\n",
      "Epoch 21/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1300 - val_loss: 0.1279\n",
      "Epoch 22/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1314 - val_loss: 0.1272\n",
      "Epoch 23/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1301 - val_loss: 0.1270\n",
      "Epoch 24/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1305 - val_loss: 0.1259\n",
      "Epoch 25/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1260 - val_loss: 0.1264\n",
      "Epoch 26/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1275 - val_loss: 0.1250\n",
      "Epoch 27/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1261 - val_loss: 0.1254\n",
      "Epoch 28/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1268 - val_loss: 0.1249\n",
      "Epoch 29/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1308 - val_loss: 0.1241\n",
      "Epoch 30/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1279 - val_loss: 0.1238\n",
      "Epoch 31/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1255 - val_loss: 0.1235\n",
      "Epoch 32/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1259 - val_loss: 0.1233\n",
      "Epoch 33/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1238 - val_loss: 0.1236\n",
      "Epoch 34/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1263 - val_loss: 0.1234\n",
      "Epoch 35/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1248 - val_loss: 0.1230\n",
      "Epoch 36/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1243 - val_loss: 0.1226\n",
      "Epoch 37/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1254 - val_loss: 0.1231\n",
      "Epoch 38/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1262 - val_loss: 0.1227\n",
      "Epoch 39/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1227 - val_loss: 0.1222\n",
      "Epoch 40/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1223 - val_loss: 0.1220\n",
      "Epoch 41/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1242 - val_loss: 0.1216\n",
      "Epoch 42/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1253 - val_loss: 0.1213\n",
      "Epoch 43/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1230 - val_loss: 0.1218\n",
      "Epoch 44/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1250 - val_loss: 0.1218\n",
      "Epoch 45/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1228 - val_loss: 0.1212\n",
      "Epoch 46/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1217 - val_loss: 0.1216\n",
      "Epoch 47/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1227 - val_loss: 0.1214\n",
      "Epoch 48/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1218 - val_loss: 0.1207\n",
      "Epoch 49/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1231 - val_loss: 0.1211\n",
      "Epoch 50/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1226 - val_loss: 0.1207\n",
      "Epoch 51/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1233 - val_loss: 0.1205\n",
      "Epoch 52/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1222 - val_loss: 0.1210\n",
      "Epoch 53/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1225 - val_loss: 0.1211\n",
      "Epoch 54/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1230 - val_loss: 0.1204\n",
      "Epoch 55/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1232 - val_loss: 0.1204\n",
      "Epoch 56/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1226 - val_loss: 0.1199\n",
      "Epoch 57/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1212 - val_loss: 0.1204\n",
      "Epoch 58/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1210 - val_loss: 0.1203\n",
      "Epoch 59/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1225 - val_loss: 0.1201\n",
      "Epoch 60/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1199 - val_loss: 0.1202\n",
      "Epoch 61/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1223 - val_loss: 0.1201\n",
      "Epoch 62/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1242 - val_loss: 0.1195\n",
      "Epoch 63/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1192 - val_loss: 0.1197\n",
      "Epoch 64/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1226 - val_loss: 0.1198\n",
      "Epoch 65/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1197 - val_loss: 0.1199\n",
      "Epoch 66/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1159 - val_loss: 0.1200\n",
      "Epoch 67/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1165 - val_loss: 0.1201\n",
      "Epoch 68/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1209 - val_loss: 0.1194\n",
      "Epoch 69/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1224 - val_loss: 0.1193\n",
      "Epoch 70/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1191 - val_loss: 0.1201\n",
      "Epoch 71/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1196 - val_loss: 0.1195\n",
      "Epoch 72/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1193 - val_loss: 0.1195\n",
      "Epoch 73/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1193 - val_loss: 0.1201\n",
      "Epoch 74/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1213 - val_loss: 0.1189\n",
      "Epoch 75/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1218 - val_loss: 0.1197\n",
      "Epoch 76/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1191 - val_loss: 0.1191\n",
      "Epoch 77/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1214 - val_loss: 0.1199\n",
      "Epoch 78/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1263 - val_loss: 0.1196\n",
      "Epoch 79/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1236 - val_loss: 0.1195\n",
      "Epoch 80/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1220 - val_loss: 0.1194\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1183 - val_loss: 0.1195\n",
      "Epoch 82/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1242 - val_loss: 0.1194\n",
      "Epoch 83/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1194 - val_loss: 0.1188\n",
      "Epoch 84/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1193 - val_loss: 0.1193\n",
      "Epoch 85/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1188 - val_loss: 0.1194\n",
      "Epoch 86/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1233 - val_loss: 0.1191\n",
      "Epoch 87/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1178 - val_loss: 0.1189\n",
      "Epoch 88/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1190 - val_loss: 0.1192\n",
      "Epoch 89/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1198 - val_loss: 0.1193\n",
      "Epoch 90/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1182 - val_loss: 0.1194\n",
      "Epoch 91/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1209 - val_loss: 0.1188\n",
      "Epoch 92/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1229 - val_loss: 0.1186\n",
      "Epoch 93/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1197 - val_loss: 0.1186\n",
      "Epoch 94/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1229 - val_loss: 0.1186\n",
      "Epoch 95/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1179 - val_loss: 0.1189\n",
      "Epoch 96/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1160 - val_loss: 0.1187\n",
      "Epoch 97/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1171 - val_loss: 0.1185\n",
      "Epoch 98/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1211 - val_loss: 0.1194\n",
      "Epoch 99/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1190 - val_loss: 0.1187\n",
      "Epoch 100/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1191 - val_loss: 0.1183\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "myInv_amp.fit(X_train_amp, y_train_amp, X_valid_amp, y_valid_amp, batch_size = 32, epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 3.7920 - val_loss: 3.0374\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.9541 - val_loss: 2.8024\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.7819 - val_loss: 2.7073\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.6849 - val_loss: 2.6633\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.6537 - val_loss: 2.6356\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.6183 - val_loss: 2.6203\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.6031 - val_loss: 2.6102\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5814 - val_loss: 2.6001\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5658 - val_loss: 2.5952\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5695 - val_loss: 2.5857\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5672 - val_loss: 2.5833\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5451 - val_loss: 2.5780\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5466 - val_loss: 2.5715\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5455 - val_loss: 2.5699\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5240 - val_loss: 2.5650\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5499 - val_loss: 2.5631\n",
      "Epoch 17/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5223 - val_loss: 2.5583\n",
      "Epoch 18/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5186 - val_loss: 2.5555\n",
      "Epoch 19/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5133 - val_loss: 2.5517\n",
      "Epoch 20/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5126 - val_loss: 2.5515\n",
      "Epoch 21/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5385 - val_loss: 2.5503\n",
      "Epoch 22/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4952 - val_loss: 2.5456\n",
      "Epoch 23/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5255 - val_loss: 2.5457\n",
      "Epoch 24/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4824 - val_loss: 2.5444\n",
      "Epoch 25/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4891 - val_loss: 2.5413\n",
      "Epoch 26/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5004 - val_loss: 2.5397\n",
      "Epoch 27/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5003 - val_loss: 2.5387\n",
      "Epoch 28/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4744 - val_loss: 2.5341\n",
      "Epoch 29/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.5046 - val_loss: 2.5340\n",
      "Epoch 30/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4721 - val_loss: 2.5327\n",
      "Epoch 31/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4786 - val_loss: 2.5291\n",
      "Epoch 32/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4819 - val_loss: 2.5283\n",
      "Epoch 33/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4764 - val_loss: 2.5269\n",
      "Epoch 34/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4705 - val_loss: 2.5269\n",
      "Epoch 35/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4900 - val_loss: 2.5260\n",
      "Epoch 36/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4747 - val_loss: 2.5227\n",
      "Epoch 37/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4626 - val_loss: 2.5246\n",
      "Epoch 38/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4745 - val_loss: 2.5196\n",
      "Epoch 39/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4674 - val_loss: 2.5208\n",
      "Epoch 40/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4747 - val_loss: 2.5200\n",
      "Epoch 41/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4489 - val_loss: 2.5174\n",
      "Epoch 42/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4908 - val_loss: 2.5160\n",
      "Epoch 43/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4937 - val_loss: 2.5177\n",
      "Epoch 44/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4625 - val_loss: 2.5151\n",
      "Epoch 45/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4511 - val_loss: 2.5139\n",
      "Epoch 46/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4746 - val_loss: 2.5126\n",
      "Epoch 47/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4589 - val_loss: 2.5124\n",
      "Epoch 48/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4682 - val_loss: 2.5123\n",
      "Epoch 49/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4575 - val_loss: 2.5114\n",
      "Epoch 50/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4918 - val_loss: 2.5103\n",
      "Epoch 51/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4651 - val_loss: 2.5097\n",
      "Epoch 52/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4595 - val_loss: 2.5083\n",
      "Epoch 53/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4462 - val_loss: 2.5069\n",
      "Epoch 54/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4503 - val_loss: 2.5071\n",
      "Epoch 55/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4493 - val_loss: 2.5076\n",
      "Epoch 56/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4469 - val_loss: 2.5068\n",
      "Epoch 57/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4634 - val_loss: 2.5054\n",
      "Epoch 58/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4336 - val_loss: 2.5055\n",
      "Epoch 59/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4764 - val_loss: 2.5004\n",
      "Epoch 60/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4568 - val_loss: 2.5018\n",
      "Epoch 61/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4549 - val_loss: 2.5012\n",
      "Epoch 62/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4422 - val_loss: 2.5013\n",
      "Epoch 63/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4527 - val_loss: 2.5017\n",
      "Epoch 64/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4609 - val_loss: 2.5031\n",
      "Epoch 65/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4422 - val_loss: 2.5017\n",
      "Epoch 66/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4476 - val_loss: 2.4997\n",
      "Epoch 67/100\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4260 - val_loss: 2.5005\n",
      "Epoch 68/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4424 - val_loss: 2.4989\n",
      "Epoch 69/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4675 - val_loss: 2.4976\n",
      "Epoch 70/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4692 - val_loss: 2.4984\n",
      "Epoch 71/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4616 - val_loss: 2.4988\n",
      "Epoch 72/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4441 - val_loss: 2.4983\n",
      "Epoch 73/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4532 - val_loss: 2.4970\n",
      "Epoch 74/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4478 - val_loss: 2.4960\n",
      "Epoch 75/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4249 - val_loss: 2.4966\n",
      "Epoch 76/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4496 - val_loss: 2.4940\n",
      "Epoch 77/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4515 - val_loss: 2.4941\n",
      "Epoch 78/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4185 - val_loss: 2.4939\n",
      "Epoch 79/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4489 - val_loss: 2.4954\n",
      "Epoch 80/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4233 - val_loss: 2.4951\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4452 - val_loss: 2.4943\n",
      "Epoch 82/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4386 - val_loss: 2.4940\n",
      "Epoch 83/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4720 - val_loss: 2.4951\n",
      "Epoch 84/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4209 - val_loss: 2.4939\n",
      "Epoch 85/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4372 - val_loss: 2.4925\n",
      "Epoch 86/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4401 - val_loss: 2.4923\n",
      "Epoch 87/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4313 - val_loss: 2.4917\n",
      "Epoch 88/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4379 - val_loss: 2.4930\n",
      "Epoch 89/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4486 - val_loss: 2.4929\n",
      "Epoch 90/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4391 - val_loss: 2.4922\n",
      "Epoch 91/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4440 - val_loss: 2.4936\n",
      "Epoch 92/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4263 - val_loss: 2.4917\n",
      "Epoch 93/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4319 - val_loss: 2.4909\n",
      "Epoch 94/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4305 - val_loss: 2.4892\n",
      "Epoch 95/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4218 - val_loss: 2.4926\n",
      "Epoch 96/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4140 - val_loss: 2.4923\n",
      "Epoch 97/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4457 - val_loss: 2.4912\n",
      "Epoch 98/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4113 - val_loss: 2.4900\n",
      "Epoch 99/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4455 - val_loss: 2.4915\n",
      "Epoch 100/100\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.4182 - val_loss: 2.4908\n"
     ]
    }
   ],
   "source": [
    "myInv_phase.fit(X_train_phase, y_train_phase, X_valid_phase, y_valid_phase, batch_size = 32, epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47248513, -0.46469423, -0.49873307, -0.4536601 , -0.5044913 ,\n",
       "        -0.46117225, -0.45426604, -0.5467412 , -0.47005236, -0.46848682,\n",
       "        -0.4567556 , -0.48530337, -0.49383712, -0.45402774, -0.47693425,\n",
       "        -0.45821887],\n",
       "       [-0.10168248, -0.1386367 , -0.18258107, -0.29929402, -0.0430944 ,\n",
       "        -0.16570908, -0.13525802, -0.19015944, -0.11099108, -0.21158667,\n",
       "        -0.1814876 , -0.15483308, -0.14375627, -0.0805324 , -0.08564842,\n",
       "        -0.15448338],\n",
       "       [-1.2861072 , -1.2695291 , -1.3132327 , -1.2577229 , -1.3348595 ,\n",
       "        -1.231543  , -1.3723589 , -1.2563733 , -1.2344033 , -1.2684028 ,\n",
       "        -1.2816248 , -1.3147794 , -1.3084613 , -1.2889698 , -1.2331805 ,\n",
       "        -1.3483095 ],\n",
       "       [-1.208308  , -1.2203457 , -1.2028427 , -1.1810404 , -1.2240746 ,\n",
       "        -1.1984922 , -1.2570475 , -1.1719648 , -1.1772426 , -1.2585676 ,\n",
       "        -1.299225  , -1.209944  , -1.1810725 , -1.2127668 , -1.235289  ,\n",
       "        -1.2368144 ]], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = myInv_amp.predict(X_test_amp)*np.exp(1j*myInv_phase.predict(X_test_phase))\n",
    "y_hat.dtype\n",
    "y_hat = myInv_amp.predict(X_test_amp)\n",
    "y_hat[1:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31758064, -0.31758064, -0.31758064, -0.31758064, -0.31758064,\n",
       "        -0.31758064, -0.31758064, -0.31758064, -0.31758064, -0.31758064,\n",
       "        -0.31758064, -0.31758064, -0.31758064, -0.31758064, -0.31758064,\n",
       "        -0.31758064],\n",
       "       [-0.08387244, -0.08387244, -0.08387244, -0.08387244, -0.08387244,\n",
       "        -0.08387244, -0.08387244, -0.08387244, -0.08387244, -0.08387244,\n",
       "        -0.08387244, -0.08387244, -0.08387244, -0.08387244, -0.08387244,\n",
       "        -0.08387244]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_amp[1:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16233379, -0.1514521 , -0.7507202 , -0.45484341, -0.64494244,\n",
       "        -0.40678551, -1.27610833,  0.85992933, -0.1536338 , -1.22413049,\n",
       "         1.45589907, -0.56846614,  0.0529663 , -0.52192677, -0.13726423,\n",
       "        -1.46106772],\n",
       "       [-0.82792304,  0.76737084, -0.42894777,  0.42505805, -0.7649639 ,\n",
       "         0.30143628,  0.29564324, -0.2335835 , -0.7662664 , -1.05038995,\n",
       "        -0.44579673, -0.16322274, -0.52352843,  0.92922641,  1.29967037,\n",
       "        -0.64297887]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_amp[1:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03924402165465134"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_test_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039310276136743955"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu] *",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
